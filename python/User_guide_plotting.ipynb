{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User guide for plotting Conformal Prediction metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install numpy pandas seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Seaborn plotting defaults\n"
     ]
    }
   ],
   "source": [
    "# Make sure to add the code to your PYTHONPATH\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from pharmbio.cp import metrics, plotting\n",
    "\n",
    "# So we can do customizations \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the results from a Conformal predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary test-case\n",
    "my_data = np.genfromtxt('test/resources/transporters.p-values.csv', delimiter=';', skip_header=1)\n",
    "true_labels = np.array([1 if x == 1.0 else 0 for x in my_data[:,1]])\n",
    "p_values=my_data[:,[2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass test-case\n",
    "from sklearn.datasets import load_iris\n",
    "multiclass_target_names = load_iris().target_names\n",
    "multiclass_data = np.genfromtxt('test/resources/multiclass.csv', delimiter=',')\n",
    "\n",
    "multiclass_p_values = multiclass_data[:,1:]\n",
    "multiclass_true_labels = multiclass_data[:,:1].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.calc_error_rate(true_labels, p_values, sign=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.calc_error_rate(multiclass_true_labels, multiclass_p_values, sign=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.calc_OF(true_labels, p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = metrics.calc_confusion_matrix(true_labels, p_values, significance=0.2, class_labels=[-1,1])\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_multiclass = metrics.calc_confusion_matrix(multiclass_true_labels, multiclass_p_values, significance=0.02, class_labels=multiclass_target_names)\n",
    "CM_multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting calibration curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_fig = plotting.plot_calibration_curve(true_labels, p_values, title='Calibration plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutliclass_fig = plotting.plot_calibration_curve(multiclass_true_labels, multiclass_p_values, title='Multiclass calibration plot', class_labels=multiclass_target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting can also be done in a smaller range of significance values and has a few parameters to tweak the generated figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_args = {'alpha': 0.75, 'marker':\"*\", 'linestyle': '-.', 'linewidth':2.5}\n",
    "\n",
    "the_fig = plotting.plot_calibration_curve(true_labels, p_values, significance_min=0.8, significance_max=.95, fig_padding=0.025,class_labels=[\"Non-Active\", \"Active\"], **line_args)\n",
    "\n",
    "# Get the axes to make custumizations on\n",
    "axes = the_fig.axes[0]\n",
    "\n",
    "# Set a custom title\n",
    "axes.set_title('My title', fontsize=22)\n",
    "\n",
    "# Remove the old legend\n",
    "axes.legend_.remove()\n",
    "\n",
    "# Add a new (custom) legend\n",
    "axes.legend(shadow=True,title='My custom Legend!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_args = {'alpha': 0.75, 'marker':\"*\", 'ms': 15,'linestyle': 'None', 'linewidth':2.5}\n",
    "\n",
    "the_fig = plotting.plot_calibration_curve(true_labels, p_values, significance_min=0.5, significance_max=1, significance_step=0.1, class_labels=[\"Non-Active\", \"Active\"],plot_all_labels=False, **line_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clibration plot for a single class, note that we will get a warning from the underlying metric that computes the error-rate for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_class_1 = (true_labels == 1)\n",
    "true_1 = true_labels[only_class_1]\n",
    "p_val_1 = p_values[only_class_1]\n",
    "the_fig = plotting.plot_calibration_curve(true_1, p_val_1, plot_all_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting distribution of prediction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_fig = plt.figure(figsize=(15,6))\n",
    "ax = my_fig.add_axes([0,0,1,1])\n",
    "custom_args = {'alpha': 0.75}\n",
    "fig = plotting.plot_label_distribution(true_labels, p_values, ax=ax, **custom_args)\n",
    "# my_fig.savefig('area-plot.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotting.plot_label_distribution(true_labels, p_values, fig_size=(15,6),display_incorrects=True, **custom_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotting.plot_label_distribution(true_labels, p_values, significance_max=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_multiclass = plotting.plot_label_distribution(multiclass_true_labels, multiclass_p_values, fig_size=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting predictions using Bubble plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the confusion matrix computed earlier\n",
    "bubble_plot = plotting.plot_confusion_matrix_bubbles(confusion_matrix=CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_plot_none = plotting.plot_confusion_matrix_bubbles(confusion_matrix=CM, color_scheme=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_plot_label = plotting.plot_confusion_matrix_bubbles(confusion_matrix=CM, color_scheme='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_plot_label = plotting.plot_confusion_matrix_bubbles(confusion_matrix=CM, color_scheme='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_plot_label_multi = plotting.plot_confusion_matrix_bubbles(confusion_matrix=CM_multiclass, color_scheme='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a normalized confusion matrix where each column sums to 1\n",
    "CM_norm = metrics.calc_confusion_matrix(true_labels, p_values, significance=0.2, class_labels=[-1,1], normalize_per_class=True)\n",
    "bubble_plot_norm = plotting.plot_confusion_matrix_bubbles(confusion_matrix=CM_norm)\n",
    "plt.title('Bubble plot', fontdict={'fontsize': 'x-large'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting heatmaps of a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_m = plotting.plot_heatmap(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_m_multi = plotting.plot_heatmap(CM_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_args = {'vmax': 1,'cmap':\"YlGnBu\"} \n",
    "cbar_kws = {\"orientation\": \"horizontal\", 'label': 'Normalized predictions'}\n",
    "heat_m_norm = plotting.plot_heatmap(CM_norm, title=\"Prediction heatmap\", cbar_kws=cbar_kws,**extra_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of joining mutliple plots in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2, figsize=(12,17))\n",
    "#fig.subplots_adjust(top=0.8)\n",
    "class_labels=['Non-binding','Binding']\n",
    "# Calibration plot\n",
    "plotting.plot_calibration_curve(true_labels, p_values, ax=axes[0,0], class_labels=class_labels)\n",
    "#70-95% confidence only\n",
    "plotting.plot_calibration_curve(true_labels, p_values, ax=axes[0,1], significance_max=.3, significance_min=0.05, fig_padding=.025, class_labels=class_labels) \n",
    "plotting.plot_confusion_matrix_bubbles(metrics.calc_confusion_matrix(true_labels,p_values, .2, class_labels=class_labels),title=\"Bubble plot\", ax=axes[1,0])\n",
    "plotting.plot_heatmap(metrics.calc_confusion_matrix(true_labels,p_values, .2, class_labels=class_labels), ax=axes[1,1])\n",
    "plotting.plot_label_distribution(true_labels,p_values, ax=axes[2,0])\n",
    "plotting.plot_label_distribution(true_labels,p_values, ax=axes[2,1], display_incorrects=True, title='Label distribution')\n",
    "fig.suptitle('Metrics plots', fontsize=20)\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "#fig.savefig('multi-plot.png',dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (PB-Seq++)",
   "language": "python",
   "name": "pbseq_seaborn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
